{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cisB24TazhU2"
   },
   "source": [
    "## Домашняя работа 5\n",
    "\n",
    "**Задание простого уровня** Мы говорили, что метрики качества нужны, чтобы сравнивать различные модели между собой. В задаче полиномиальной регрессии реализуйте код для выбора лучшей степени полиному:\n",
    "\n",
    "* возьмите все степени от 1 до 10 по порядку, без пропусков.\n",
    "* найдите степень полинома будет лучший r2-score\n",
    "* напишите код, который выводит самую подходящую степень полинома и соответствующий ей скор\n",
    "\n",
    "Эта процедура называется Grid Search и помогает найти лучшие параметры для модели.\n",
    "\n",
    "Обучите лучшую модель и сделайте predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yAOKZYMNzhU4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшая степень полинома - 10, R2 = 0.9000272171779298\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "%matplotlib inline\n",
    "df=pd.read_csv('non_linear.csv')\n",
    "\n",
    "def x_degree(x: list, degree: int):\n",
    "    return np.array([x**d for d in range(1, degree+1)]).T\n",
    "\n",
    "def polinom_regr(features:list, result:list, degree: int):\n",
    "    X=x_degree(features, degree)\n",
    "    R=LinearRegression().fit(X, df.y_train)\n",
    "    y_pred=R.predict(X)\n",
    "    return r2_score(y_pred,result)\n",
    "\n",
    "def best_polinom(features:list, result:list, degree: int):\n",
    "        scores=[polinom_regr(features, result, i) for i in range(1,degree+1)]\n",
    "        print (f'Лучшая степень полинома - {scores.index(max(scores))+1}, R2 = {max(scores)}')  \n",
    "\n",
    "best_polinom(df['x_train'], df.y_train, 10)      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z3dSmlAFzhU9"
   },
   "source": [
    "**Задание среднего уровня** Напишите класс для обучения модели, который содержит:\n",
    "\n",
    "* функцию `.fit(X, y)` , которая принимает на вход массив фичей `X`, массив таргетов `y` и обучает коэффициенты регрессии. Код для обучения взять из первого урока модуля *Постановка ML задачи линейной регрессии*\n",
    "* функцию `.predict(X)`, которая по массиву фичей `X` возвращает массив предсказаний `y`\n",
    "\n",
    "Нужно использовать код для аналитически вычисяемых коэффициентов. \n",
    "\n",
    "Это задание позволит понять, как работает линейная регрессия \"внутри\" библиотечной реализации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rayvZFx1zhU9"
   },
   "outputs": [],
   "source": [
    "class CustomLinearReg:\n",
    "    from numpy.linalg import inv\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        X_T_X = (X.T).dot(X)\n",
    "        X_T_X_inverted = inv(X_T_X)\n",
    "        self.w = X_T_X_inverted.dot(X.T).dot(y)\n",
    "        return self\n",
    "    def predict(self, X):\n",
    "        return (self.w[0]+X*self.w[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[1, 50],[1, 60],[1, 70],[1, 100]])\n",
    "x = np.array([[50],[60],[70],[100]])\n",
    "y = np.array([[10],[30],[40],[50]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'inv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-1cbe644121c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCustomLinearReg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-df342203b1af>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mX_T_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mX_T_X_inverted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_T_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_T_X_inverted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'inv' is not defined"
     ]
    }
   ],
   "source": [
    "model=CustomLinearReg().fit(X,y)\n",
    "model.predict(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uwWP7aPOzhVA"
   },
   "source": [
    "**Задание высокого уровня**\n",
    "\n",
    "1. разделите датасет с домами Бостона из Урока 2 (таргет и фичи) на две части: в одной части 80% датасета (назовём train) в другой 20% (назовём valid)\n",
    "1. обучите модель только на train датасете\n",
    "1. постройте предсказания valid датасете\n",
    "1. Посчитайте  `r2 score` на валидационном сете\n",
    "\n",
    "После этого примените к обеим датасетам z-преобразование и повторите шаги 2-4. Как изменилась метрика r2?\n",
    "\n",
    "Это задание поможет понять, как валидировать линейную регрессию (и другие модели) на отложенной выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "boston_dataset = load_boston()\n",
    "\n",
    "features = boston_dataset.data\n",
    "y = boston_dataset.target\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(features, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7553646253100434"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train=LinearRegression().fit(x_train, y_train)\n",
    "valid=train.predict(x_valid)\n",
    "r2_score(valid,y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.5062020969734953"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_tr=StandardScaler().fit_transform(features)\n",
    "y_tr=StandardScaler().fit_transform(y.reshape(-1,1)).reshape(-1)\n",
    "x_train_tr, x_valid_tr, y_train_tr, y_valid_tr = train_test_split(features_tr, y, test_size=0.2)\n",
    "train_tr=LinearRegression().fit(x_train_tr, y_train_tr)\n",
    "valid_tr=train.predict(x_valid_tr)\n",
    "r2_score(valid_tr,y_valid_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-4.253446150257274"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_tr=StandardScaler().fit_transform(features)\n",
    "y_tr=StandardScaler().fit_transform(y.reshape(-1,1)).reshape(-1)\n",
    "x_train_tr, x_valid_tr, y_train_tr, y_valid_tr = train_test_split(features_tr, y_tr, test_size=0.2)\n",
    "train_tr=LinearRegression().fit(x_train_tr, y_train_tr)\n",
    "valid_tr=train.predict(x_valid_tr)\n",
    "r2_score(valid_tr,y_valid_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После применения z-преобразования метрика сильно ухудшилась. При обычных данных r2_score=0.66, после преобразования всего датасета получается -4.20, если преобразовать только фичи, то -0.11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "jun_ml_linear_regression_I-hw5.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
