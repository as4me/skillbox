{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BRRejAlppFwP"
   },
   "source": [
    "# Обучение нейронной сети\n",
    "\n",
    "Это последняя и самая важная практика в этом блоке. В ней вы соберете воедино все, что мы с вами изучили и примените для создания сети, которая классифицирует рукописные цифры.\n",
    "\n",
    "Задание будет состоять из следующих этапов:\n",
    "1.  Реализация слоя ReLU\n",
    "2.  Реализация полносвязного слоя\n",
    "3.  Написание обучающего цикла\n",
    "4.  Загрузка данных и обучение сети\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow-estimator in /Users/andreysergeev/opt/anaconda3/envs/tensor/lib/python3.8/site-packages (2.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pip install tensorflow-estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ZpTEvkPqxqk"
   },
   "source": [
    "**Задание 1**\n",
    "Написание слоя ReLU. В этом задании вы реализуете слой нейронной сети, который вычисляет поэлементно функцию ReLU:\n",
    "\n",
    "$$\n",
    "ReLU(x) = max(0, x)\n",
    "$$\n",
    "\n",
    "и выгядит следующим образом:\n",
    "\n",
    "![alt text](https://miro.medium.com/max/536/1*oePAhrm74RNnNEolprmTaQ.png)\n",
    "\n",
    "Нетрудно заметить, что производная при $x > 0$ равна $1$, а при $x < 0$ равна $0$. Это вам пригодится при реализации backward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "XKoIb3NpLAqj"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.misc import derivative\n",
    "from typing import List\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from IPython.display import clear_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 130
    },
    "id": "7fiEdDgzLFiH",
    "outputId": "9ce90d56-4f98-4392-fbb3-96edb9d50071"
   },
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    \"\"\"\n",
    "    Базовый класс слоя нашей нейронной сети. \n",
    "    Все слои должны наследоваться от него и реализовывать два метода: forward и backward\n",
    "    \"\"\"\n",
    "    def forward(self, x):\n",
    "        pass\n",
    "    def backward(self, dL_dz, learning_rate=0):\n",
    "        pass\n",
    "\n",
    "class ReLU(Layer):\n",
    "    \"\"\"\n",
    "    Слой ReLU\n",
    "    \"\"\"\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Метод, который вычисляет ReLU(x)\n",
    "\n",
    "        Размер выхода должен совпадать со входом\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        self._saved_input = x # нам необходимо сохранить вход\n",
    "        output = None\n",
    "\n",
    "        # < YOUR CODE STARTS HERE >\n",
    "        output = np.maximum(0,x)\n",
    "        # переменная output должна содержать выход ReLU\n",
    "        \n",
    " \n",
    "        # < YOUR CODE ENDS HERE >\n",
    "        assert output.shape == x.shape\n",
    "        return output\n",
    "\n",
    "    def backward(self, dL_dz, learning_rate=0.):\n",
    "        \"\"\"\n",
    "        dL_dz -- производная финальной функции по выходу этого слоя.\n",
    "                 Размерость должна в точности соответствовать размерности\n",
    "                 x, который прошел в forward pass.\n",
    "        learning_rate -- не используется, т.к. ReLU не содержит параметров.\n",
    "\n",
    "        Метод должен посчитать производную dL_dx.\n",
    "        Благодаря chain rule, мы знаем, что dL_dx = dL_dz * dz_dx\n",
    "        и при этом dL_dz нам известна.\n",
    "\n",
    "        Для слоя relu, dz_dx(x) = 1, при x > 0, и dz_dz = 0 при x < 0\n",
    "        \n",
    "        * сохраненный инпут находится в self._saved_input\n",
    "        \"\"\"\n",
    "        dz_dx = None\n",
    "        \n",
    "        # < YOUR CODE STARTS HERE >\n",
    "        # переменная dz_dx должна содержать производную выхода ReLU по ее входу\n",
    "        \n",
    "        dz_dx = np.where(self._saved_input < 0, 0,1)\n",
    "        \n",
    "        # < YOUR CODE ENDS HERE >\n",
    "        assert dz_dx.shape == self._saved_input.shape, f\"Shapes must be the same. Got {dz_dx.shape, self._saved_input.shape}\"\n",
    "        output = dz_dx * dL_dz\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "OWFBXJGPz_zt"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f9fc0fcc250>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "relu = ReLU()\n",
    "\n",
    "# убедитесь, что график соответствует представленному вверху\n",
    "plt.plot(np.linspace(-1, 1, 100), relu.forward(np.linspace(-1, 1, 100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "aH8pmNuI3BBP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test passed\n"
     ]
    }
   ],
   "source": [
    "f = lambda x: ReLU().forward(x)\n",
    "\n",
    "x = np.linspace(-1, 1, 10*32).reshape([10, 32])\n",
    "l = ReLU()\n",
    "l.forward(x)\n",
    "grads = l.backward(np.ones([10, 32]))\n",
    "numeric_grads = derivative(f, x, dx=1e-6)\n",
    "assert np.allclose(grads, numeric_grads, rtol=1e-3, atol=0),\\\n",
    "     \"gradient returned by your layer does not match the numerically computed gradient\"\n",
    "print(\"Test passed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ddzfoKcogJfE"
   },
   "source": [
    "**Задание 2** Реализация полносвязного слоя. \n",
    "\n",
    "Закончите реализацию метода forward для полносвязного слоя"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Q5DQKmPuqKUp"
   },
   "outputs": [],
   "source": [
    "class FCLayer(Layer):\n",
    "    \"\"\"\n",
    "    Полносвязный (fully connected/dense) слой\n",
    "    \"\"\"\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        \"\"\"\n",
    "        in_dim, out_dim -- количество входных и выходных нейронов соответственно\n",
    "        \"\"\"\n",
    "        self.in_dim = in_dim\n",
    "        self.out_dim = out_dim\n",
    "        # инициализируем матрицу весов (in_dim,out_dim) нормальным распределением\n",
    "        self.weights = np.random.randn(in_dim,out_dim)*0.001\n",
    "\n",
    "        # инициализируем смещение нулями\n",
    "        self.bias = np.zeros(self.out_dim)\n",
    "        self._saved_input = None\n",
    "    \n",
    "    def forward(self, x: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Вычисление выхода полносвязного слоя.\n",
    "\n",
    "        x -- вход слоя, размерности (N, in_dim), где N -- количество объектов \n",
    "             в батче\n",
    "\n",
    "        return: matmul(x, weights) + bias\n",
    "        \"\"\"\n",
    "        assert np.ndim(x) == 2\n",
    "        assert x.shape[1] == self.in_dim\n",
    "        self._saved_input = x\n",
    "\n",
    "        # < YOUR CODE STARTS HERE >\n",
    "        # переменная output должна содержать выход полносвязного слоя\n",
    "        \n",
    "        output = np.matmul(self._saved_input,self.weights) + self.bias\n",
    "        \n",
    "        # < YOUR CODE ENDS HERE >\n",
    "\n",
    "        assert output.shape == (x.shape[0], self.out_dim), (output.shape, (x.shape[0], self.out_dim))\n",
    "        return output\n",
    "    \n",
    "    def backward(self, dL_dz, learning_rate=0.):\n",
    "        \"\"\"\n",
    "        dL_dz -- производная финальной функции по выходу этого слоя.\n",
    "                 Размерость (N, self.out_dim).\n",
    "        learning_rate -- если отличен от нуля, то с вызовом этой функции, параметры\n",
    "                         слоя (weights, bias) будут обновлены\n",
    "\n",
    "        Метод должен посчитать производную dL_dx.\n",
    "        \n",
    "        \"\"\"\n",
    "        assert np.ndim(dL_dz) == 2\n",
    "        assert dL_dz.shape[1] == self.out_dim\n",
    "        \n",
    "        # очень рекомендуем понять почему это так,\n",
    "        # хорошее объяснение здесь: http://cs231n.stanford.edu/handouts/linear-backprop.pdf\n",
    "        self.dL_dw = np.dot(self._saved_input.T, dL_dz)\n",
    "        self.dL_dx = np.dot(dL_dz, self.weights.T)\n",
    "        self.dL_db = dL_dz.sum(0) \n",
    "        \n",
    "        assert self.dL_db.shape == self.bias.shape\n",
    "        assert self.dL_dw.shape == self.weights.shape\n",
    "        assert self.dL_dx.shape == self._saved_input.shape\n",
    "\n",
    "        if learning_rate != 0:\n",
    "            # знакомый вам шаг градиентного спуска!\n",
    "            self.weights -= learning_rate * self.dL_dw\n",
    "            self.bias -= learning_rate * self.dL_db\n",
    "        \n",
    "        return self.dL_dx\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pREQ8CMW_Bcw"
   },
   "source": [
    "Теперь перейдем к вычислению лосса. Т.к. перед нами стоит задача мультиклассовой классификации, то мы будем использовать multiclass_cross_entropy_loss, который мы рассмотрели на лекции.\n",
    "Такой лосс на одном объекте $i$, который принадлежит к классу $k$ будет равен: \n",
    "$$\n",
    "loss_i = -log(p_i^k),\n",
    "$$\n",
    "где $p_i^k$ -- предсказанная вероятность того, что $i$ый объект принадлежит к классу $k$.\n",
    "\n",
    "Для того, чтобы получить вероятности, мы использовали Softmax, примененный в логитам выходного слоя. Т.е. \n",
    "$$\n",
    "p_i^k = \\frac{exp(logit_k)}{\\sum_{j=0}^{m} exp(logit_j)}\n",
    "$$\n",
    "\n",
    "А значит лосс можно переписать так:\n",
    "$$\n",
    "loss_i = -log(p_i^k) = -logit_k + log(\\sum_{j=0}^{m} exp(logit_j))\n",
    "$$\n",
    "\n",
    "Как мы помним, сеть изначально предсказывает логиты, и затем мы превращаем их в вероятности. Но т.к. мы знаем, что нам предстоит считать лосс, то мы можем не тратить \"силы\" на вычисление вероятностей и посчитать лосс основываясь на логитах. Такая запись проще и вычислительно более стабильная. \n",
    "\n",
    "Ниже мы приводим готовую реализацию лосса и его градиента."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "c5b5T9VG1ohv"
   },
   "outputs": [],
   "source": [
    "def multiclass_crossentropy_with_logits(logits, y_true):\n",
    "    \"\"\"\n",
    "    logits -- выход нейронной сети без активации. Размерность: (N, k),\n",
    "              где N -- количество объектов, k -- количество классов\n",
    "    y_true -- реальные классы для N объектов\n",
    "\n",
    "    Класс возвращает вектор из лоссов на каждом объекте\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    logits_for_answers = logits[np.arange(len(logits)), y_true]\n",
    "    \n",
    "    cross_entropy = -logits_for_answers + np.log(np.sum(np.exp(logits),axis=-1))\n",
    "    \n",
    "    return cross_entropy\n",
    "\n",
    "def grad_multiclass_crossentropy_with_logits(logits, y_true):\n",
    "    \"\"\"\n",
    "     logits -- выход нейронной сети без активации. Размерность: (N, k),\n",
    "              где N -- количество объектов, k -- количество классов\n",
    "    y_true -- реальные классы для N объектов\n",
    "\n",
    "    Класс возвращает матрицу производных.\n",
    "    \n",
    "    \"\"\"\n",
    "    ones_for_answers = np.zeros_like(logits)\n",
    "    ones_for_answers[np.arange(len(logits)), y_true] = 1\n",
    "    \n",
    "    softmax = np.exp(logits) / np.exp(logits).sum(axis=-1,keepdims=True)\n",
    "    \n",
    "    return (- ones_for_answers + softmax) / logits.shape[0]    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WH5c18IUgtj5"
   },
   "source": [
    "**Задание 3** Реализация класса  Network.\n",
    "\n",
    "В этом задании вам предлагается реализовать методы forward(), predict(), train_step(). Это последний шаг перед тем как наша сеть будет готова!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "F-H0nTyx1lTH"
   },
   "outputs": [],
   "source": [
    "class Network:\n",
    "    \"\"\"\n",
    "    Нейронная сеть\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, layers: List[Layer]):\n",
    "        \"\"\"\n",
    "        Для инициализации нейронной сети, нам нужен список слоев, которые должны\n",
    "        быть последовательно применены друг к другу. \n",
    "\n",
    "        \"\"\"\n",
    "        self.layers = layers\n",
    "    \n",
    "    def forward(self, x: np.ndarray):\n",
    "        \"\"\"\n",
    "        x -- входной батч объектов размера (N, размер_входа_первого_слоя)\n",
    "        \n",
    "        Получив x на вход, сеть должна по-очереди применить к нему все слои.\n",
    "        Т.е. выход каждого слоя является входом следующего.\n",
    "\n",
    "        x -> layer_0 -> layer_1 ... -> last_layer\n",
    "\n",
    "        \"\"\"\n",
    "        output = None\n",
    "        # < YOUR CODE STARTS HERE >\n",
    "        # Реализуйте последовательное применение forward методов каждого из \n",
    "        # слоев (self.layers)\n",
    "        output = self.layers[0].forward(x)\n",
    "        for i in range(len(self.layers) - 1):\n",
    "            output = self.layers[i+1].forward(output)\n",
    "\n",
    "\n",
    "\n",
    "        # < YOUR CODE ENDS HERE >\n",
    "        \n",
    "        return output\n",
    "\n",
    "    def predict(self, x):\n",
    "        \"\"\"\n",
    "        x -- входной батч объектов размера (N, размер_входа_первого_слоя)\n",
    "        \n",
    "        Функция должна вернуть вектор размера (N) с номером предсказанного класса\n",
    "        для каждого объекта. \n",
    "\n",
    "        \"\"\"\n",
    "        logits = self.forward(x) # считаем логиты сделав полный форвард пасс сети\n",
    "        # напомним, что размер логитов (N, k), где k -- количество классов\n",
    "        \n",
    "        classes = None\n",
    "        # < YOUR CODE STARTS HERE >\n",
    "        # реализуйте получение классов из логитов. вам может пригодится \n",
    "        # метод argmax\n",
    "\n",
    "        classes = np.argmax(logits,axis=-1)\n",
    "\n",
    "        # < YOUR CODE ENDS HERE >\n",
    "\n",
    "        assert classes.shape == (x.shape[0],)\n",
    "        return classes\n",
    "    \n",
    "    def train_step(self, x, y, learning_rate):\n",
    "        \"\"\"\n",
    "        x -- входной батч объектов размера (N, размер_входа_первого_слоя)\n",
    "        y -- реальные классы объектов (N,)\n",
    "        \"\"\"\n",
    "        logits = self.forward(x)\n",
    "        loss = multiclass_crossentropy_with_logits(logits, y)\n",
    "        loss_grad = grad_multiclass_crossentropy_with_logits(logits, y)\n",
    "        \n",
    "        # < YOUR CODE STARTS HERE >\n",
    "        # Выше мы получили loss_grad. Теперь его нужно \"пробросить\" через всю сеть\n",
    "        # вызывая backward каждого слоя в обратном порядке.\n",
    "        # Не забудьте передать в backward -- learning rate.\n",
    "        # loss_grad -> last_layer.backward(loss_grad, lr) -> ... --> layer_0.backward(loss_grad_from_layer_1, lr)\n",
    "\n",
    "        \n",
    "        for i in range(len(self.layers)-1, -1, -1):\n",
    "            loss_grad = self.layers[i].backward(loss_grad,learning_rate)\n",
    "        \n",
    "        # < YOUR CODE ENDS HERE >\n",
    "\n",
    "        return np.mean(loss)\n",
    "    \n",
    "    def fit(self, x_train, y_train, x_test, y_test, learning_rate, num_epochs, \n",
    "            batch_size):\n",
    "        \"\"\"\n",
    "        Цикл обучения уже реализован. Основная его задача -- итерироваться по \n",
    "        минибатчам и вызывать на каждом из них train_step, который вы уже реализовали.\n",
    "\n",
    "        В остальном -- это логирование лосса, точности и отрисовка графика.\n",
    "\n",
    "        \"\"\"\n",
    "        train_log = []\n",
    "        test_log = []\n",
    "        loss_log = []\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            loss_iters = []\n",
    "            for x_batch,y_batch in iterate_minibatches(x_train, y_train, \n",
    "                                                       batchsize=batch_size, shuffle=True):\n",
    "                loss_iters.append(self.train_step(x_batch, y_batch, learning_rate=learning_rate))\n",
    "\n",
    "            loss_log.append(np.mean(loss_iters)) # для визуализации усредняем лосс за каждую итерацию\n",
    "            train_accuracy = accuracy_score(y_train, self.predict(x_train))\n",
    "            test_accuracy = accuracy_score(y_test, self.predict(x_test))\n",
    "            train_log.append(train_accuracy)\n",
    "            test_log.append(test_accuracy)\n",
    "\n",
    "            clear_output()\n",
    "            print(\"Epoch\", epoch)\n",
    "            print(\"Train accuracy:\",train_log[-1])\n",
    "            print(\"Test accuracy:\",test_log[-1])\n",
    "            plt.figure(figsize=(10, 5))\n",
    "            ax1 = plt.subplot(1,2,1)    \n",
    "            plt.plot(train_log,label='train accuracy')\n",
    "            plt.plot(test_log,label='test accuracy')\n",
    "            ax2 = plt.subplot(1,2,2)\n",
    "            plt.plot(loss_log,label='loss')\n",
    "            ax1.legend(loc='best')\n",
    "            ax2.legend(loc='best')\n",
    "            plt.grid()\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "def iterate_minibatches(inputs, targets, batchsize, shuffle=False):\n",
    "    assert len(inputs) == len(targets)\n",
    "    if shuffle:\n",
    "        indices = np.random.permutation(len(inputs))\n",
    "    for start_idx in tqdm(range(0, len(inputs) - batchsize + 1, batchsize)):\n",
    "        if shuffle:\n",
    "            batch_indexes = indices[start_idx:start_idx + batchsize]\n",
    "        else:\n",
    "            batch_indexes = slice(start_idx, start_idx + batchsize)\n",
    "            \n",
    "        yield inputs[batch_indexes], targets[batch_indexes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QirWyEeEPS3w"
   },
   "source": [
    "## Обучение\n",
    "На этом этапе наша сеть полностью описаны и готова к бою. Нам нужны теперь только данные.\n",
    "\n",
    "Мы поставим перед собой задачу классифицировать изображения рукописных цифр. Они представляют собой картинки размера (28, 28). Для использования нашей сети мы превратим их в строчки длины $28*28 = 784$.\n",
    "\n",
    "Давайте посмотрим как они выглядят:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "aHeWIyY4fER3"
   },
   "outputs": [],
   "source": [
    "def show_mnist(images, labels, predicted_labels=None):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    for i in range(16):\n",
    "        plt.subplot(4,4, i+1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        plt.imshow(images[i], cmap=plt.cm.gray)\n",
    "        if predicted_labels is not None:\n",
    "            title_obj = plt.title(f\"Real: {labels[i]}. Pred: {predicted_labels[i]}\")\n",
    "            if labels[i] != predicted_labels[i]:\n",
    "                plt.setp(title_obj, color='r')\n",
    "        else:\n",
    "            plt.title(f\"Real label: {labels[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Prp9Oo0mhNbf"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/jx/llrt2xqd2l149cf7xwmcx2w00000gn/T/ipykernel_57199/2359428889.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mshow_mnist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.metrics import accuracy_score\n",
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "show_mnist(train_images, train_labels)\n",
    "\n",
    "# преобразуем изображения к нужному виду\n",
    "train_images = train_images.reshape(train_images.shape[0], -1).astype('float32') / 255.\n",
    "test_images = test_images.reshape(test_images.shape[0], -1).astype('float32') / 255.\n",
    "print(train_images.shape, test_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JFTgCXa4QQZm"
   },
   "outputs": [],
   "source": [
    "# Наша сеть будет состоять из одного скрытого слоя\n",
    "layers = []\n",
    "layers.append(FCLayer(train_images.shape[1], 100)) # входной слой\n",
    "layers.append(ReLU()) # активация\n",
    "layers.append(FCLayer(100, 200)) # скрытый слой\n",
    "layers.append(ReLU()) # активация\n",
    "layers.append(FCLayer(200, 10)) # выходной слой -- 10 классов (10 цифр). Обратите внимание, мы не используем активацию!\n",
    "                                # т.к. лосс рассчитывает на логиты, а не вероятности\n",
    "\n",
    "# инициализируем наш класс указанными слоями\n",
    "net = Network(layers=layers)\n",
    "# если все реализовано правильно -- точность на отложенной части выборки достигнет 97%\n",
    "net.fit(x_train=train_images, y_train=train_labels, \n",
    "        x_test=test_images, y_test=test_labels,\n",
    "        batch_size=32, num_epochs=10, learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HfOs96iPfJCj"
   },
   "outputs": [],
   "source": [
    "predicted_labels = net.predict(test_images)\n",
    "idxs = np.random.choice(np.arange(len(test_images)), 16, replace=False)\n",
    "show_mnist(test_images[idxs].reshape((-1, 28, 28)), test_labels[idxs], predicted_labels[idxs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "homework_2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
