{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o9BZlZjCI6Nw"
   },
   "source": [
    "# Градиентный спуск\n",
    "\n",
    "В этом практическом занятии вы реализуете градиентный спуск самостоятельно. На сегодняшний день -- это основной способ оптимизации нейронных сетей.\n",
    "\n",
    "Мы начнем с простой функции -- парабола, затем перейдем к чуть более сложной."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "6NdsVzyU6BvR"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1jrE7v_ZQfK-"
   },
   "source": [
    "**Задание 1**\n",
    "\n",
    "Закончите реализацию алгоритма градиентного спуска. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "4cV_3uyWJXVB"
   },
   "outputs": [],
   "source": [
    "def gradient_descent(f: callable, df_dx: callable, initial_position: float, n_iters: int, lr: float,\n",
    "                     tol: float = 1e-3):\n",
    "    \"\"\"\n",
    "    Алгоритм градиентного спуска. \n",
    "\n",
    "    f -- функция, минимум которой мы хотим найти\n",
    "    df_dx -- производная функции по x\n",
    "    initial_position -- начальное приближение\n",
    "    n_iters -- максимальное количество шагов градиентного спуска\n",
    "    lr -- learning rate, скорость обучения\n",
    "    tol -- точность с которой мы будем считать, что значение функции не меняется\n",
    "    \n",
    "    Функция должна вернуть найденный минимум, историю положений\n",
    "    и значений функции \n",
    "    \"\"\"\n",
    "    positions = []\n",
    "    values = []\n",
    "    position = initial_position\n",
    "    for i in range(n_iters):\n",
    "        positions.append(position)\n",
    "        values.append(f(position))\n",
    "        if len(values) > 1:\n",
    "            if np.abs(values[-1] - values[-2]) < tol:\n",
    "                break\n",
    "        \n",
    "        # < YOUR CODE STARTS HERE >\n",
    "        # Реализуйте шаг градиентного спуска. \n",
    "        position = position - lr*df_dx[position]\n",
    "        # < YOUR CODE ENDS HERE >\n",
    "\n",
    "    print(f\"Found minimum at x={position} after {len(positions) - 1} steps.\")\n",
    "    return position, positions, values\n",
    "\n",
    "def visualize(f: callable, limits: tuple, positions: list, values: list):\n",
    "    xs = np.linspace(limits[0], limits[1], 100)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(xs, f(xs))\n",
    "    plt.title(f\"Найденный минимум после {len(positions) - 1} шагов: $f = {values[-1]:.2}$ при $x = {positions[-1]:.2}$\")\n",
    "    _, = plt.plot(positions, values)\n",
    "    for p, v in zip(positions, values):\n",
    "        plt.scatter(p, v, s=30, zorder=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "NiHHXucn6f1T"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'function' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-96e5622bdf4a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m position, positions, values = gradient_descent(f=f, df_dx=df_dx, initial_position=initial_position, \n\u001b[0m\u001b[1;32m     10\u001b[0m                                                n_iters=n_iters, lr=lr, tol=1e-4)\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-b70f9f77c945>\u001b[0m in \u001b[0;36mgradient_descent\u001b[0;34m(f, df_dx, initial_position, n_iters, lr, tol)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m# < YOUR CODE STARTS HERE >\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m# Реализуйте шаг градиентного спуска.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mposition\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mposition\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdf_dx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mposition\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;31m# < YOUR CODE ENDS HERE >\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'function' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "f = lambda x: x**2 + x + 1 # функция для оптимизации\n",
    "df_dx = lambda x: 2*x + 1 # производная\n",
    "\n",
    "lr = 0.3\n",
    "n_iters = 20\n",
    "initial_position = -4.\n",
    "\n",
    "\n",
    "position, positions, values = gradient_descent(f=f, df_dx=df_dx, initial_position=initial_position, \n",
    "                                               n_iters=n_iters, lr=lr, tol=1e-4)\n",
    "\n",
    "visualize(f, (-4, 3), positions=positions, values=values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cellView": "both",
    "id": "6-nf4o4695AC"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-10-375369000b09>, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-10-375369000b09>\"\u001b[0;36m, line \u001b[0;32m7\u001b[0m\n\u001b[0;31m    df_dx =\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# градиентный спуск\n",
    "initial_position = -4 \n",
    "f = lambda x: (x**2 - 4*x + 4)*(x**2 + 4*x + 2)\n",
    "\n",
    "# < YOUR CODE STARTS HERE>\n",
    "# Напишите, чему равна производная f по x\n",
    "df_dx = \n",
    "# < YOUR CODE ENDS HERE>\n",
    "\n",
    "# < YOUR CODE STARTS HERE>\n",
    "# Выберите подходящие параметры для оптимизации\n",
    "n_iters =  \n",
    "lr = \n",
    "# < YOUR CODE ENDS HERE>\n",
    "\n",
    "\n",
    "position, positions, values = gradient_descent(f=f, df_dx=df_dx, initial_position=initial_position, \n",
    "                                               n_iters=n_iters, lr=lr, tol=1e-4)\n",
    "visualize(f, (-4, 4), positions=positions, values=values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iz_U7XdgTtn4"
   },
   "source": [
    "**Задание 2**\n",
    "Продемонстрируйте на примере функции выше:\n",
    "1. застревание в локальном минимуме (выберете другое начальное приближение)\n",
    "2. расхождение оптимизации (попробуйте другую скорость обучения)\n",
    "\n",
    "Скопируйте код из клетки выше в две последующие и оставьте графики для оценки и демонстрации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iMI3pff4THuR"
   },
   "outputs": [],
   "source": [
    "# Задание 2.1\n",
    "\n",
    "# градиентный спуск\n",
    "initial_position = 3 \n",
    "f = lambda x: (x**2 - 4*x + 4)*(x**2 + 4*x + 2)\n",
    "\n",
    "# < YOUR CODE STARTS HERE>\n",
    "# Напишите, чему равна производная f по x\n",
    "df_dx = \n",
    "# < YOUR CODE ENDS HERE>\n",
    "\n",
    "# < YOUR CODE STARTS HERE>\n",
    "# Выберите подходящие параметры для оптимизации\n",
    "n_iters =  \n",
    "lr = \n",
    "# < YOUR CODE ENDS HERE>\n",
    "\n",
    "\n",
    "position, positions, values = gradient_descent(f=f, df_dx=df_dx, initial_position=initial_position, \n",
    "                                               n_iters=n_iters, lr=lr, tol=1e-4)\n",
    "visualize(f, (-4, 4), positions=positions, values=values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fQWqtuzXTMuB"
   },
   "outputs": [],
   "source": [
    "# Задание 2.1\n",
    "\n",
    "# градиентный спуск\n",
    "initial_position = 0\n",
    "f = lambda x: (x**2 - 4*x + 4)*(x**2 + 4*x + 2)\n",
    "\n",
    "# < YOUR CODE STARTS HERE>\n",
    "# Напишите, чему равна производная f по x\n",
    "df_dx = \n",
    "# < YOUR CODE ENDS HERE>\n",
    "\n",
    "# < YOUR CODE STARTS HERE>\n",
    "# Выберите подходящие параметры для оптимизации\n",
    "n_iters =  \n",
    "lr = \n",
    "# < YOUR CODE ENDS HERE>\n",
    "\n",
    "\n",
    "position, positions, values = gradient_descent(f=f, df_dx=df_dx, initial_position=initial_position, \n",
    "                                               n_iters=n_iters, lr=lr, tol=1e-4)\n",
    "visualize(f, (-4, 4), positions=positions, values=values)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "practice_5_gd.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
